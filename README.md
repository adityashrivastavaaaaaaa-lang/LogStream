# LogStream

A high-performance, scalable log ingestion and search system built with modern technologies. LogStream can handle thousands of logs per second with real-time processing and full-text search capabilities.

## ğŸš€ Features

- **High Performance**: Processes 901 logs per second (54,083 logs per minute)
- **Real-time Processing**: Asynchronous log ingestion via Kafka message queue
- **Full-text Search**: Fast search across all log fields and metadata
- **Scalable Architecture**: Microservices design with Docker containers
- **Web Dashboard**: User-friendly interface for log management
- **PostgreSQL Storage**: Reliable, ACID-compliant log storage
- **RESTful API**: Clean API endpoints for integration

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend  â”‚    â”‚     API     â”‚    â”‚   Worker    â”‚
â”‚   (Nginx)   â”‚â—„â”€â”€â–ºâ”‚  (FastAPI)  â”‚â—„â”€â”€â–ºâ”‚  (Python)   â”‚
â”‚             â”‚    â”‚             â”‚    â”‚             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                   â”‚                   â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚  Database   â”‚
                   â”‚ (PostgreSQL)â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â–²
                           â”‚
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚    Kafka    â”‚
                   â”‚  (Message   â”‚
                   â”‚   Queue)    â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ Tech Stack

- **Backend**: FastAPI (Python)
- **Database**: PostgreSQL
- **Message Queue**: Apache Kafka
- **Frontend**: HTML/CSS/JavaScript with Nginx
- **Containerization**: Docker & Docker Compose
- **Load Testing**: Custom Python script

## ğŸ“‹ Prerequisites

- Docker and Docker Compose
- Python 3.8+ (for load testing)
- Git

## ğŸš€ Quick Start

1. **Clone the repository**
   ```bash
   git clone https://github.com/adityashrivastavaaaaaaa-lang/LogStream.git
   cd LogStream
   ```

2. **Start the system**
   ```bash
   docker-compose up --build
   ```

3. **Access the services**
   - **Web Dashboard**: http://localhost:8080
   - **API**: http://localhost:8000
   - **API Documentation**: http://localhost:8000/docs

## ğŸ“– API Usage

### Health Check
```bash
curl http://localhost:8000/
```

### Ingest a Log
```bash
curl -X POST http://localhost:8000/ingest \
  -H "Content-Type: application/json" \
  -d '{
    "level": "info",
    "service": "api",
    "message": "User login successful"
  }'
```

### Search Logs
```bash
# Get all logs (limited to 10)
curl "http://localhost:8000/search"

# Search with query
curl "http://localhost:8000/search?q=error&limit=50"
```

## ğŸ§ª Load Testing

Test the system's performance with the included load tester:

```bash
python3 load_tester.py 10000
```

This will send 10,000 logs concurrently and measure performance metrics.

## ğŸ“ Project Structure

```
LogStream/
â”œâ”€â”€ api/                    # FastAPI service
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ worker/                 # Kafka consumer worker
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ worker.py
â”œâ”€â”€ frontend/               # Web dashboard
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ index.html
â”œâ”€â”€ db/                     # Database initialization
â”‚   â””â”€â”€ init.sql
â”œâ”€â”€ docker-compose.yml      # Service orchestration
â”œâ”€â”€ load_tester.py          # Performance testing script
â”œâ”€â”€ TODO.md                 # Development notes
â””â”€â”€ README.md
```

## ğŸ”§ Configuration

All services are configured through environment variables in `docker-compose.yml`:

- **API**: Kafka and database connection settings
- **Worker**: Kafka consumer configuration
- **Database**: PostgreSQL credentials
- **Kafka**: Broker and topic settings

## ğŸ“Š Performance Benchmarks

- **Throughput**: 901 logs/second (54,083 logs/minute)
- **Latency**: Sub-second response times
- **Concurrency**: Handles 100+ concurrent connections
- **Storage**: Efficient PostgreSQL indexing for fast queries

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- Built with FastAPI, PostgreSQL, Kafka, and Docker
- Inspired by modern logging and observability systems
- Performance tested with custom load testing tools

---

**LogStream** - High-performance logging for the modern era ğŸš€
